#!/usr/bin/env python3
"""
Vertica Pre & Post-upgrade Schema Comparison Program
Interactive version with comparison and backup functionality
Modified to handle multiple nodes in Vertica cluster
Updated to include Vertica Libraries information
Modified to save only CSV files for backup
Enhanced with KVM/OS level configuration validation
Fixed to properly display failed OS checks in CSV output
"""

import vertica_python
import csv
import json
import pandas as pd
from datetime import datetime
import os
import sys
import zipfile
import tarfile
import pickle
from typing import List, Dict, Any, Optional, Tuple
import argparse
import getpass
import subprocess
import platform
import warnings
import re
import paramiko
from io import StringIO

# Suppress vertica_python TLS warnings
warnings.filterwarnings("ignore", category=UserWarning, module="vertica_python")


class VerticaSchemaExtractor:
    def __init__(self, host: str, port: int, username: str, password: str, database: str):
        """
        Initialize Vertica connection parameters

        Args:
            host: Vertica server hostname
            port: Vertica server port
            username: Database username
            password: Database password
            database: Database name
        """
        self.connection_info = {
            'host': host,
            'port': port,
            'user': username,
            'password': password,
            'database': database,
            'read_timeout': 600,
            'unicode_error': 'strict',
            'tlsmode': 'disable'  # Disable TLS to avoid warnings
        }
        self.connection = None
        self.vertica_host = host

    def execute_os_level_check(self, ssh_username: str = "deployment") -> Dict[str, Any]:
        """
        Execute KVM/OS level configuration check on Vertica VM

        Args:
            ssh_username: SSH username for Vertica VM
            ssh_password: SSH password for Vertica VM

        Returns:
            Dictionary containing OS level check results
        """
        try:
            # Create SSH client
            ssh_client = paramiko.SSHClient()
            ssh_client.set_missing_host_key_policy(paramiko.AutoAddPolicy())

            # Connect to Vertica VM
            ssh_client.connect(
                hostname=self.vertica_host,
                username=ssh_username,
                timeout=30
            )

            # Execute the vertica local verify command
            command = "sudo /opt/vertica/oss/python3/bin/python3 -m vertica.local_verify"
            stdin, stdout, stderr = ssh_client.exec_command(command)

            # Read the output
            output = stdout.read().decode('utf-8')
            error_output = stderr.read().decode('utf-8')

            # Close SSH connection
            ssh_client.close()

            # Parse the output
            return self._parse_os_check_output(output, error_output)

        except Exception as e:
            print(f"âš  Error executing OS level check: {str(e)}")
            return {
                'summary': {'pass': 0, 'fail': 0},
                'failed_checks': [],
                'raw_output': f"Error: {str(e)}"
            }

    def _parse_os_check_output(self, output: str, error_output: str) -> Dict[str, Any]:
        """
        Parse the output from vertica.local_verify command

        Args:
            output: Command output
            error_output: Command error output

        Returns:
            Parsed results dictionary
        """
        try:
            # Combine output and error output
            full_output = output + "\n" + error_output

            # Initialize result structure
            result = {
                'summary': {'pass': 0, 'fail': 0},
                'failed_checks': [],
                'raw_output': full_output
            }

            # Extract summary information
            pass_match = re.search(r'pass:\s*(\d+)', full_output, re.IGNORECASE)
            if pass_match:
                result['summary']['pass'] = int(pass_match.group(1))

            fail_match = re.search(r'fail:\s*(\d+)', full_output, re.IGNORECASE)
            if fail_match:
                result['summary']['fail'] = int(fail_match.group(1))

            # Extract failed checks - look for lines containing "FAIL"
            failed_checks = []
            lines = full_output.split('\n')

            for line in lines:
                line = line.strip()
                if 'FAIL' in line and line.startswith('#'):
                    # This is a failed check line
                    # Extract the meaningful part of the failure
                    failed_checks.append(line)
                elif 'FAIL' in line and ('S0' in line or 'eS0' in line):
                    # This might be a failure message on a separate line
                    failed_checks.append(line)

            # If we didn't find specific failed checks but have a fail count > 0,
            # look for any line containing failure information
            if not failed_checks and result['summary']['fail'] > 0:
                for line in lines:
                    line = line.strip()
                    if ('FAIL' in line.upper() and
                        any(keyword in line.lower() for keyword in ['limit', 'kbytes', 'too low', 'not within', 'specified'])):
                        failed_checks.append(line)

            result['failed_checks'] = failed_checks
            return result

        except Exception as e:
            print(f"âš  Error parsing OS check output: {str(e)}")
            return {
                'summary': {'pass': 0, 'fail': 0},
                'failed_checks': [],
                'raw_output': f"Parse error: {str(e)}\n\nOriginal output:\n{output}\n\nError output:\n{error_output}"
            }

    def save_combined_csv(self, data: Dict[str, List[Dict[str, Any]]], filename: str, os_check_data: Optional[Dict[str, Any]] = None):
        """Save all sections into a single CSV file with section titles"""
        try:
            with open(filename, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.writer(csvfile)

                section_map = {
                    'projection_columns': "Below is the Schema Projection Columns Details",
                    'users': "Below is the User / Resource Pool Details",
                    'configuration_parameters': "Below is the Vertica recommended configuration on DB level Details",
                    'vertica_libraries': "Below is the Vertica Libraries Details"
                }

                # Add database sections
                for section_key, section_title in section_map.items():
                    records = data.get(section_key, [])
                    if not records:
                        continue

                    # Section header
                    writer.writerow([])
                    writer.writerow([f"------------- {section_title} -------------"])
                    writer.writerow([])

                    # Table content
                    fieldnames = records[0].keys()
                    writer.writerow(fieldnames)
                    for row in records:
                        writer.writerow([row.get(field, "") for field in fieldnames])

                # Add OS level check results
                if os_check_data:
                    writer.writerow([])
                    writer.writerow(["------------- Below is the KVM/OS Level Configuration Details -------------"])
                    writer.writerow([])

                    # Summary
                    writer.writerow(["Summary Status", "Count"])
                    writer.writerow(["Pass", os_check_data['summary']['pass']])
                    writer.writerow(["Fail", os_check_data['summary']['fail']])
                    writer.writerow([])

                    # Show failed checks or success message
                    if os_check_data['summary']['fail'] > 0 and os_check_data['failed_checks']:
                        writer.writerow(["Failed Checks Details"])
                        writer.writerow(["Check Description"])
                        for check in os_check_data['failed_checks']:
                            writer.writerow([check])
                    else:
                        writer.writerow(["All OS level checks passed"])

            print(f"âœ“ Combined CSV saved: {filename}")
            return True

        except Exception as e:
            print(f"âœ— Error writing combined CSV: {str(e)}")
            return False

    def connect(self):
        """Establish connection to Vertica database"""
        try:
            self.connection = vertica_python.connect(**self.connection_info)
            #print(f"âœ“ Connected to Vertica database: {self.connection_info['database']}")
            return True
        except Exception as e:
            print(f"âœ— Error connecting to Vertica: {str(e)}")
            return False

    def disconnect(self):
        """Close database connection"""
        if self.connection:
            self.connection.close()
            print("âœ“ Disconnected from Vertica database")

    def execute_schema_query(self, env_version: str = "13.3", table_pattern: str = "CDR_S1AP") -> Dict[str, List[Dict[str, Any]]]:
        """
        Execute the schema comparison queries and configuration validation
        """
        projection_query = """
        SELECT table_schema,
               table_name,
               table_column_name,
               data_type,
               encoding_type,
               sort_position
        FROM projection_columns
        GROUP BY table_schema, table_name, table_column_name, data_type, encoding_type, sort_position
        ORDER BY sort_position DESC
        """

        users_query = """
        SELECT user_name,
               search_path,
               resource_pool
        FROM users
        ORDER BY user_name
        """

        config_query = """
        SELECT * FROM configuration_parameters WHERE current_value <> default_value
        """

        libraries_query = """
        SELECT lib_name FROM user_libraries
        ORDER BY lib_name
        """

        try:
            cursor = self.connection.cursor()

            def run_query(query):
                cursor.execute(query)
                columns = [desc[0] for desc in cursor.description]
                return [dict(zip(columns, row)) for row in cursor.fetchall()]

            projection_data = run_query(projection_query)
            users_data = run_query(users_query)
            config_data = run_query(config_query)
            libraries_data = run_query(libraries_query)

            cursor.close()

            print(f"âœ“ Retrieved {len(projection_data)} projection records")
            print(f"âœ“ Retrieved {len(users_data)} user records")
            print(f"âœ“ Retrieved {len(config_data)} config parameter records")
            print(f"âœ“ Retrieved {len(libraries_data)} library records")

            return {
                'projection_columns': projection_data,
                'users': users_data,
                'configuration_parameters': config_data,
                'vertica_libraries': libraries_data
            }

        except Exception as e:
            print(f"âœ— Error executing query: {str(e)}")
            return {
                'projection_columns': [],
                'users': [],
                'configuration_parameters': [],
                'vertica_libraries': []
            }

    def save_to_csv(self, data: Dict[str, List[Dict[str, Any]]], filename: str, silent: bool = False):
        """Save schema data to CSV file with multiple sheets"""
        if not data or not any(data.values()):
            if not silent:
                print("âš  No data to save")
            return False

        try:
            # For CSV, we'll create separate files for each data type
            base_filename = filename.replace('.csv', '')
            files_created = []

            for data_type, records in data.items():
                if records:
                    type_filename = f"{base_filename}_{data_type}.csv"
                    with open(type_filename, 'w', newline='', encoding='utf-8') as csvfile:
                        fieldnames = records[0].keys()
                        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                        writer.writeheader()
                        writer.writerows(records)
                    files_created.append(type_filename)

            if not silent:
                for file in files_created:
                    print(f"âœ“ Schema data saved to CSV: {file}")
            return True

        except Exception as e:
            if not silent:
                print(f"âœ— Error saving to CSV: {str(e)}")
            return False

    def save_to_json(self, data: Dict[str, List[Dict[str, Any]]], filename: str, silent: bool = False):
        """Save schema data to JSON file"""
        if not data or not any(data.values()):
            if not silent:
                print("âš  No data to save")
            return False

        try:
            with open(filename, 'w', encoding='utf-8') as jsonfile:
                json.dump(data, jsonfile, indent=2, default=str)

            if not silent:
                print(f"âœ“ Schema data saved to JSON: {filename}")
            return True

        except Exception as e:
            if not silent:
                print(f"âœ— Error saving to JSON: {str(e)}")
            return False

    def save_to_excel(self, data: Dict[str, List[Dict[str, Any]]], filename: str, silent: bool = False):
        """Save schema data to Excel file with multiple sheets"""
        if not data or not any(data.values()):
            if not silent:
                print("âš  No data to save")
            return False

        try:
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                for data_type, records in data.items():
                    if records:
                        df = pd.DataFrame(records)
                        df.to_excel(writer, sheet_name=data_type, index=False)

            if not silent:
                print(f"âœ“ Schema data saved to Excel: {filename}")
            return True

        except Exception as e:
            if not silent:
                print(f"âœ— Error saving to Excel: {str(e)}")
            return False

    def save_to_pickle(self, data: Dict[str, List[Dict[str, Any]]], filename: str, silent: bool = False):
        """Save schema data to pickle file for backup purposes"""
        if not data or not any(data.values()):
            if not silent:
                print("âš  No data to save")
            return False

        try:
            with open(filename, 'wb') as picklefile:
                pickle.dump(data, picklefile)

            if not silent:
                print(f"âœ“ Schema data saved to Pickle: {filename}")
            return True

        except Exception as e:
            if not silent:
                print(f"âœ— Error saving to Pickle: {str(e)}")
            return False

    def create_archive(self, files_to_archive: List[str], archive_name: str, archive_type: str = "zip"):
        """
        Create archive with specified files

        Args:
            files_to_archive: List of file paths to include in archive
            archive_name: Name of the archive file
            archive_type: Type of archive ('zip' or 'tar')
        """
        try:
            if archive_type.lower() == "zip":
                with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file_path in files_to_archive:
                        if os.path.exists(file_path):
                            zipf.write(file_path, os.path.basename(file_path))
                            print(f"  âœ“ Added {file_path} to archive")
                        else:
                            print(f"  âš  File not found: {file_path}")

            elif archive_type.lower() == "tar":
                with tarfile.open(archive_name, 'w:gz') as tarf:
                    for file_path in files_to_archive:
                        if os.path.exists(file_path):
                            tarf.add(file_path, arcname=os.path.basename(file_path))
                            print(f"  âœ“ Added {file_path} to archive")
                        else:
                            print(f"  âš  File not found: {file_path}")

            print(f"âœ“ Archive created: {archive_name}")
            return True

        except Exception as e:
            print(f"âœ— Error creating archive: {str(e)}")
            return False

    def create_archive_silent(self, files_to_archive: List[str], archive_name: str):
        """
        Create ZIP archive silently without verbose output

        Args:
            files_to_archive: List of file paths to include in archive
            archive_name: Name of the archive file
        """
        try:
            with zipfile.ZipFile(archive_name, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in files_to_archive:
                    if os.path.exists(file_path):
                        zipf.write(file_path, os.path.basename(file_path))
            return True

        except Exception as e:
            print(f"âœ— Error creating archive: {str(e)}")
            return False

    def cleanup_temp_files_silent(self, files_to_delete: List[str]):
        """Clean up temporary files silently"""
        for file_path in files_to_delete:
            try:
                if os.path.exists(file_path):
                    os.remove(file_path)
            except Exception:
                pass  # Silent cleanup - ignore errors


def ping_host(hostname):
    """
    Ping the hostname to check connectivity

    Args:
        hostname: The hostname to ping

    Returns:
        bool: True if ping successful, False otherwise
    """
    try:
        # Determine ping command based on OS
        if platform.system().lower() == "windows":
            cmd = ["ping", "-n", "3", hostname]
        else:
            cmd = ["ping", "-c", "3", hostname]

        # Execute ping command
        result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
        return result.returncode == 0

    except Exception as e:
        print(f"âš  Error during ping: {str(e)}")
        return False


def get_hostname():
    """
    Interactive function to get hostname with ping verification

    Returns:
        str: Verified hostname or None if user chooses to exit
    """
    print("\n" + "="*60)
    print("    VERTICA SCHEMA EXTRACTION TOOL")
    print("="*60)

    while True:
        print("\n" + "-"*40)
        print("Connection Setup:")
        print("-"*40)

        hostname = input("Enter Vertica hostname/IP: ").strip()

        if not hostname:
            print("âš  Hostname cannot be empty. Please try again.")
            continue

        print(f"\nðŸ” Checking connectivity to {hostname}...")

        if ping_host(hostname):
            print("âœ“ Connection OK")
            return hostname
        else:
            print("âœ— Vertica Not Available")
            print("\nOptions:")
            print("1. Try another hostname")
            print("2. Exit")

            while True:
                try:
                    choice = int(input("\nEnter your choice (1 or 2): ").strip())
                    if choice == 1:
                        break
                    elif choice == 2:
                        return None
                    else:
                        print("Please enter either 1 or 2")
                except ValueError:
                    print("Please enter a valid number (1 or 2)")


def get_user_input():
    """Interactive function to get user preferences"""

    # Get hostname with ping verification
    hostname = get_hostname()
    if not hostname:
        print("\nðŸ‘‹ Goodbye!")
        return None

    # Fixed connection parameters
    username = "dbadmin"
    password = "dbadmin"
    port = 5433
    database = "vdb"

    # Fixed query parameters
    env_version = "13.3"
    table_pattern = "CDR_S1AP"

    # Get purpose
    print("\n" + "-"*40)
    print("Select the purpose to run the program:")
    print("-"*40)
    print("1. Create Report for comparison")
    print("2. Create Report for Backup")

    while True:
        try:
            purpose = int(input("\nEnter your choice (1 or 2): ").strip())
            if purpose in [1, 2]:
                break
            else:
                print("Please enter either 1 or 2")
        except ValueError:
            print("Please enter a valid number (1 or 2)")

    # Fixed output format - CSV only for both comparison and backup
    output_format = 'csv'
    archive_format = None

    return {
        'purpose': purpose,
        'host': hostname,
        'port': port,
        'username': username,
        'password': password,
        'database': database,
        'env_version': env_version,
        'table_pattern': table_pattern,
        'output_format': output_format,
        'archive_format': archive_format
    }


def main():
    """Main interactive function"""
    try:
        # Get user input
        config = get_user_input()

        # Check if user chose to exit
        if config is None:
            return

        print("\n" + "="*60)
        print("    PROCESSING...")
        print("="*60)

        # Create schema extractor
        extractor = VerticaSchemaExtractor(
            host=config['host'],
            port=config['port'],
            username=config['username'],
            password=config['password'],
            database=config['database']
        )

        # Connect to database
        if not extractor.connect():
            print("\nâœ— Failed to connect to database. Exiting...")
            return

        try:
            # Remove verbose processing messages for backup
            if config['purpose'] == 1:  # Only show for comparison
                print(f"\nðŸ” Executing schema query...")
            schema_data = extractor.execute_schema_query(config['env_version'], config['table_pattern'])

            if not schema_data:
                print("âœ— No schema data retrieved. Exiting...")
                return

            # Execute OS level check
            if config['purpose'] == 1:  # Only show for comparison
                print(f"\nðŸ” Executing KVM/OS level configuration check...")

            os_check_data = extractor.execute_os_level_check()

            if config['purpose'] == 1:  # Only show for comparison
                if os_check_data['summary']['fail'] > 0:
                    print(f"âœ“ OS level check completed - Summary: pass: {os_check_data['summary']['pass']}, fail: {os_check_data['summary']['fail']}")
                    if os_check_data['failed_checks']:
                        print("Failed checks:")
                        for check in os_check_data['failed_checks']:
                            print(f"  - {check}")
                else:
                    print(f"âœ“ OS level check completed - Summary: pass: {os_check_data['summary']['pass']}, fail: {os_check_data['summary']['fail']}")
                    print("All OS level checks passed!")

            # Generate timestamp for filenames
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            base_filename = f"vertica_schema_Pre_{timestamp}"

            if config['purpose'] == 1:  # Only show for comparison
                print(f"\nðŸ“Š Processing {sum(len(v) for v in schema_data.values())} records...")

            if config['purpose'] == 1:  # Comparison Report
                print(f"\nðŸ“„ Creating comparison report in CSV format...")

                csv_file = f"../Reports/Vertica_Pre_Validation_Report_{datetime.now().strftime('%d%m%y%H%M%S')}.csv"
                if extractor.save_combined_csv(schema_data, csv_file, os_check_data):
                    print(f"\nâœ… Comparison report created successfully inside Reports Directory !")
                    print(f"ðŸ“ File created: {csv_file}")
                else:
                    print(f"\nâœ— Failed to create comparison report")

            else:  # Backup Report - Only CSV format
                print(f"\nðŸ’¾ Creating backup file in CSV format...")

                # Save the combined CSV file directly to Archive directory
                csv_file = f"../Archive/Vertica_Pre_Validation_Report_{datetime.now().strftime('%d%m%y%H%M%S')}.csv"

                if extractor.save_combined_csv(schema_data, csv_file, os_check_data):
                    print(f"\nâœ… Backup file created successfully inside Archive Directory !")
                    print(f"ðŸ“ File created: {csv_file}")
                else:
                    print(f"\nâœ— Failed to create backup file")

        finally:
            extractor.disconnect()

        print(f"\n" + "="*60)
        print("    PROCESS COMPLETED")
        print("="*60)

    except KeyboardInterrupt:
        print(f"\n\nâš  Process interrupted by user")
    except Exception as e:
        print(f"\nâœ— Unexpected error: {str(e)}")


if __name__ == "__main__":
    # Check if running with command line arguments
    if len(sys.argv) > 1:
        print("Command line mode detected. Use interactive mode by running without arguments.")
        print("For interactive mode, run: python vertica_schema_comparison.py")
    else:
        main()
